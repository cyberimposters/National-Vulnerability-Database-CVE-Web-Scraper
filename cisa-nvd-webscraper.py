#!/usr/bin/python3

import bs4
import requests
import re
import os
import hashlib


def bulletins():
### this is a list of variables referencing the text document  
  bulletins_list = open('bulletins-list.txt') # this is the bulletins list file
  bulletins_list_output = open('bulletins-out.txt' , 'w') # this is a results output file
  lines = bulletins_list.readline() 

### this is the end of text document list

  for lines in bulletins_list: # example of using for-loop to read line-by-line from a given file
    html = "https://www.cisa.gov/uscert/ncas/bulletins/"
    webpage = requests.get(html + lines.strip())
    soup = bs4.BeautifulSoup(webpage.text, "html.parser")
    details_box = soup.find(attrs={'class':'cert-content'})
    print(details_box, file = bulletins_list_output)

bulletins()
  
def bulletins_text_cleanup(): # this strips the html elements out of the initial output

  bulletins_list_output_html = open('bulletins-out.txt')
  bulletins_list_output_clean = open('bulletins-clean.txt' , 'a')
  read_html = bulletins_list_output_html.read()
  str = read_html
  match = re.compile(r'<.*?>')
  cleantext = match.sub('', str)
  print(cleantext, file = bulletins_list_output_clean)

bulletins_text_cleanup()

def create_cve_list_bulletins(): # this grabs the CVEs from the "clean" text document

  bulletins_list_clean = open('bulletins-clean.txt')
  bulletins_cve_list = open('bulletins-cve-list.txt' , 'w')
  read_clean = bulletins_list_clean.read()
  str2 = read_clean
  strings = re.findall(r'CVE-\d\d\d\d-\d*', str2)
  for i in strings:
      print (i , file = bulletins_cve_list)

create_cve_list_bulletins()

def alerts():
  ### this is a list of variables referencing the text document  
  alerts_list = open('alerts-list.txt') # this is the alerts list file
  alerts_list_output = open('alerts-out.txt' , 'w') # this is a results output file
  lines = alerts_list.readline() 

### this is the end of text document list

  for lines in alerts_list: # example of using for-loop to read line-by-line from a given file
    html = "https://www.cisa.gov/uscert/ncas/alerts/"
    webpage = requests.get(html + lines.strip())
    soup = bs4.BeautifulSoup(webpage.text, "html.parser")
    details_box = soup.find(id ='ncas-content')
    print(details_box, file = alerts_list_output)

alerts()

def alerts_text_cleanup(): # this strips the html elements out of the initial output

  alerts_list_output_html = open('alerts-out.txt')
  alerts_list_output_clean = open('alerts-clean.txt' , 'a')
  read_html = alerts_list_output_html.read()
  str = read_html
  match = re.compile(r'<.*?>')
  cleantext = match.sub('', str)
  print(cleantext, file = alerts_list_output_clean)

alerts_text_cleanup()  

def create_cve_list_alerts(): # this grabs the CVEs from the "clean" text document

  alerts_list_clean = open('alerts-clean.txt')
  alerts_cve_list = open('alerts-cve-list.txt' , 'w')
  read_clean = alerts_list_clean.read()
  str2 = read_clean
  strings = re.findall(r'CVE-\d\d\d\d-\d*', str2)
  for i in strings:
      print (i , file = alerts_cve_list)

create_cve_list_alerts()

def cleanup():
  
  os.remove('bulletins-clean.txt')
  os.remove('alerts-clean.txt')
  os.remove('bulletins-out.txt')
  os.remove('alerts-out.txt')

  alerts_file = open('alerts-cve-list.txt')
  read_alerts_file = alerts_file.read()
  print("This is a list of alerts provided by cisa.gov.\n" + "\n" + read_alerts_file)

  bulletin_file = open('bulletins-cve-list.txt')
  read_bulletin_file = bulletin_file.read()
  print("This is a list of bulletin provided by cisa.gov.\n" + "\n" + read_bulletin_file)

cleanup()

def combine_alerts_bulletins(): # Python program merging of two files | this combines the CVEs

  user_input = input("Would you like to research the CVEs via the National Vulnerability Database? ")
  user_input_case = user_input.lower()

  if user_input_case == "y":

    data = data2 = ""

    with open('alerts-cve-list.txt') as fp: # Reading data from file1
	    data = fp.read()

    with open('bulletins-cve-list.txt') as fp: # Reading data from file2
	    data2 = fp.read()
  # Merging 2 files
  # To add the data of file2
    data += data2

    with open ('combined-cve-list.txt', 'w') as fp:
	    fp.write(data)

  elif user_input_case == "n":
    print("\nYou have chosen to exit the script.")
    exit()

combine_alerts_bulletins()


def check_duplicates(): # This removes duplicates from CVE list
  
  output_file_path = "combined-cve-list-hash.txt"
  input_file_path = "combined-cve-list.txt"

  completed_lines_hash = set()
  output_file = open(output_file_path, "w")

  for line in open(input_file_path, "r"):
    hashValue = hashlib.md5(line.rstrip().encode('utf-8')).hexdigest()

    if hashValue not in completed_lines_hash:
      output_file.write(line)
      completed_lines_hash.add(hashValue)

  output_file.close()
check_duplicates()

def nvd_check():
  try:
    user_input = input("Type 'NIST' for the NIST Score or 'CNA' for the Vendor Risk Score: ")
    user_input_case = user_input.lower()

    if user_input_case == "nist":

        file = open('combined-cve-list-hash.txt') # this is the CVE list file
        output = open('nist_out.txt' , 'a') # this is a results output file 'append to file'
        lines = file.readline() 


        for lines in file: # example of using for-loop to read line-by-line from a given file
          html = "https://nvd.nist.gov/vuln/detail/"
          webpage = requests.get(html + lines.strip())
          soup = bs4.BeautifulSoup(webpage.text, "html.parser")
          # looks for NIST calc scores
          content_box = soup.find(id="Cvss3NistCalculatorAnchor")
        #this is the vulnerability description
          details_box = soup.find(attrs={'data-testid':'vuln-description'}) or soup.find(attrs={'data-testid':'service-unavailable-msg'})

          while content_box:
            content = content_box.text
            details_box = soup.find(attrs={'data-testid':'vuln-description'})
            details = details_box.text
            print(lines + "\nNIST Risk Score: " + content)
            print("\nDetails: " + details)
            print(lines.strip("\n") + " " + content + " " + "Details: " + details, file = output)
            print("----------\n")
            break

          else: #ratings attribute is empty
            html = "https://nvd.nist.gov/vuln/detail/"
            webpage = requests.get(html + lines.strip())
            soup = bs4.BeautifulSoup(webpage.text, "html.parser")
            details_box = soup.find(attrs={'data-testid':'vuln-description'}) or soup.find(attrs={'data-testid':'service-unavailable-msg'})
            details = details_box.text
            print(lines + "\nNIST Risk Score: Not Yet Rated V3.x:(not available) " + "\nDetails: " + details)
            print(lines.strip("\n") + " " + "Not Yet Rated " + "Details: " + details, file = output)
            print("----------\n")

        output.close() # Closes the output file.
        file.close()

        print ("\nYou have reached then end of your list.") #End of list

        file = open("nist_out.txt", "r")
        #read content of file to string
        data = file.read()
        #get number of occurrences 
        occurrences_nyr = data.count("Not Yet Rated")
        occurrences_critical = data.count("CRITICAL")
        occurrences_high = data.count("HIGH")
        occurrences_medium = data.count("MEDIUM")
        occurrences_low = data.count("LOW")
        print('\nNumber of "Not Yet Rated" :', occurrences_nyr)
        print('Number of "CRITICAL" :', occurrences_critical)
        print('Number of "HIGH" :', occurrences_high)
        print('Number of "MEDIUM" :', occurrences_medium)
        print('Number of "LOW" :', occurrences_low)

    elif user_input_case == "cna":

      file = open('combined-cve-list-hash.txt') # this is the CVE list file
      output = open('vendor_out.txt' , 'a') # this is a results output file 'append to file'
      lines = file.readline() 


      for lines in file: # example of using for-loop to read line-by-line from a given file
        html = "https://nvd.nist.gov/vuln/detail/"
        webpage = requests.get(html + lines.strip())
        soup = bs4.BeautifulSoup(webpage.text, "html.parser")
        content_box = soup.find(id="Cvss3CnaCalculatorAnchor")
      #this is the vulnerability description
        details_box = soup.find(attrs={'data-testid':'vuln-description'}) or soup.find(attrs={'data-testid':'service-unavailable-msg'})

        while content_box:
          content = content_box.text
          details_box = soup.find(attrs={'data-testid':'vuln-description'})
          details = details_box.text
          print(lines + "\nVendor Risk Score: " + content)
          print("\nDetails: " + details)
          print(lines.strip("\n") + " " + content + " " + "Details: " + details, file = output)
          print("----------\n")
          break

        else: #ratings attribute is empty
          html = "https://nvd.nist.gov/vuln/detail/"
          webpage = requests.get(html + lines.strip())
          soup = bs4.BeautifulSoup(webpage.text, "html.parser")
          details_box = soup.find(attrs={'data-testid':'vuln-description'}) or soup.find(attrs={'data-testid':'service-unavailable-msg'})
          details = details_box.text
          print(lines + "\nVendor Risk Score: Not Yet Rated V3.x:(not available) " + "\nDetails: " + details)
          print(lines.strip("\n") + " " + "Not Yet Rated " + "Details: " + details, file = output)
          print("----------\n")

      output.close() # Closes the output file.
      file.close()

      print ("\nYou have reached then end of your list.") #End of list

      file = open("vendor_out.txt", "r") #read content of file to string
      data = file.read()
      #get number of occurrences 
      occurrences_nyr = data.count("Not Yet Rated")
      occurrences_critical = data.count("CRITICAL")
      occurrences_high = data.count("HIGH")
      occurrences_medium = data.count("MEDIUM")
      occurrences_low = data.count("LOW")
      print('\nNumber of "Not Yet Rated" :', occurrences_nyr)
      print('Number of "CRITICAL" :', occurrences_critical)
      print('Number of "HIGH" :', occurrences_high)
      print('Number of "MEDIUM" :', occurrences_medium)
      print('Number of "LOW" :', occurrences_low)
    
  except AttributeError:
      print("Error: One of the CVEs in your list is formatted incorrectly. See the example below for the proper formatting.\n\nCVE-YYYY-###\n\nPlease review your list and remove or modify the CVE list then re-run the script.\n")
      return nvd_check()
  else:
    print("\nYour entry was invalid. Please provide one of the following: NIST, nist, CNA, or cna.\n")
    return nvd_check()

nvd_check()
